{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44186cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d1483d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = torch.nn.Conv2d(1, 256, kernel_size=(12, 5), padding=(0, int(5 / 2)))\n",
    "        self.gru = torch.nn.RNN(256, 256, batch_first=True)\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(256, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, num_classes),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)                # (N, 1, H, W) => (N, 256, 1, W)\n",
    "        x = x.squeeze(2)                # (N, 256, 1, W) => (N, 256, W)\n",
    "        x = torch.permute(x, (0, 2, 1)) # (N, 256, W) =>  (N, W, 256)\n",
    "        _, hn = self.gru(x)             # (1, N, 256)\n",
    "        hn = hn.squeeze(0)              # (1, N, 256) => (N, 256)\n",
    "        x = self.fc(hn)                 # (N, 256) => (N, 12)\n",
    "        return torch.nn.functional.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23bd3e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 Examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 Loss:2.481394052505493\n",
      "Epoch #2 Loss:2.442871332168579\n",
      "Epoch #3 Loss:2.389258623123169\n",
      "Epoch #4 Loss:2.30055570602417\n",
      "Epoch #5 Loss:2.1826696395874023\n",
      "Epoch #6 Loss:2.0382473468780518\n",
      "Epoch #7 Loss:1.881241798400879\n",
      "Epoch #8 Loss:1.7519906759262085\n",
      "Epoch #9 Loss:1.6737626791000366\n",
      "Epoch #10 Loss:1.6384851932525635\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_data(1)\n",
    "def reshape_for_cnn(X):\n",
    "    \"\"\"\n",
    "    Reshapes the data from (X_LEN, B_SZ, X_DIM) (e.g. (5000, 10, 12))\n",
    "    to (B_SZ, 1, X_DIM, X_LEN), because we have 1 channel.\n",
    "    \"\"\"\n",
    "    W, N, H = X.shape\n",
    "    X = torch.permute(X, (1, 2, 0))\n",
    "    X = torch.reshape(X, (N, 1, H, W))\n",
    "    return X\n",
    "\n",
    "X = reshape_for_cnn(X)\n",
    "\n",
    "N, C, H, W = X.shape\n",
    "\n",
    "mdl = ConvRNN(12)\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr = 1e-3, weight_decay = 1e-8)\n",
    "\n",
    "# Train\n",
    "N_EPOCHS = 10\n",
    "BATCH_SZ = 1\n",
    "for e_i in range(N_EPOCHS):\n",
    "    \n",
    "    # shuffle the indices\n",
    "    idx = np.arange(N)\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    # iterate over batches\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = N // BATCH_SZ\n",
    "    for b_i in range(num_batches):\n",
    "        \n",
    "        # Make batch.\n",
    "        X_batch = X[idx[b_i * BATCH_SZ : (b_i + 1) * BATCH_SZ],:,:,:]\n",
    "        Y_batch = Y[idx[b_i * BATCH_SZ : (b_i + 1) * BATCH_SZ],:]\n",
    "        \n",
    "        # Zero gradients.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass.\n",
    "        pred = mdl.forward(X_batch)\n",
    "        \n",
    "        # Calculate loss.\n",
    "        loss = torch.nn.functional.cross_entropy(pred, Y_batch)\n",
    "        \n",
    "        # Compute gradients.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters.\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print Loss.\n",
    "    print(\"Epoch #{0} Loss:{1}\".format(e_i + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Test the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
